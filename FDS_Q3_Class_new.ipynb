{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Document Similarity\n",
    "Create a python program that will compute the text document similarity between different docu- ments. Your implementation will take a list of documents as an input text corpus, and it will compute a dictionary of words for the given corpus. Later, when a new document (i.e, search document) is provided, your implementation should provide a list of documents that are similar to the given search document, in descending order of their similarity with the search document.\n",
    "For computing similarity between any two documents in our question, you can use the following distance measures (optionally, you can also use any other measure as well).\n",
    "1. dot product between the two vectors\n",
    "2. distance norm (or Euclidean distance) between two vectors .e.g. || u âˆ’ v ||\n",
    "\n",
    "As part of answering the question, you can also compare and comment on which of the two methods (or any other measure if you have used some other measure) will perform better and what are the reasons for it.\n",
    "\n",
    "Hint A text document can be represented as a word vector against a given dictionary of words. So first, compute the dictionary of words for a given text corpus containing the unique words from the documents of the given corpus. Then transform every text document of the given corpus into vector form, i.e., creating a word vector where 0 indicates the word is not in the document, and 1 indicates that the word is present in the given document. In our question, a text document is just represented as a string, so the text corpus is nothing but a list of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class DocumentSimilarityAnalyzer:\n",
    "    def __init__(self, directory):\n",
    "        self.dictionary = set()\n",
    "        self.corpus = [] #list of strings -> appended in the \"update corpus\" function\n",
    "        self.name_list = [] #list of strings -> appended in the \"update name\" function -> used to get document names\n",
    "        if Path(directory).is_dir() == True: self.directory = directory\n",
    "        else: print(\"Inputted path is not valid. Please check your input.\")\n",
    "        self.corpus = [] #list of strings -> appended in the \"update corpus\" function\n",
    "        self.name_list = [] #list of strings -> appended in the \"update name\" function -> used to get document names\n",
    "        \n",
    "    def print_dictionary(self): \n",
    "        print(self.dictionary)\n",
    "    \n",
    "    def print_corpus(self):\n",
    "        print(self.corpus)\n",
    "    \n",
    "    def print_name(self): \n",
    "        print(self.name_list)\n",
    "    \n",
    "    def clear_corpus(self):\n",
    "        self.corpus.clear()\n",
    "\n",
    "    def clear_name_list(self):\n",
    "        self.name_list.clear()\n",
    "\n",
    "    def load_search_doc(self, doc_name): #function to load the search document from drive\n",
    "        \n",
    "        #open file by using path() -> to make it operateable on windows and mac systems\n",
    "        assert Path(self.directory+doc_name).is_file(), \"The inputted file does not exist at that directory.\"\n",
    "        file = Path(self.directory + doc_name)\n",
    "        \n",
    "        #open and read search file\n",
    "        #throw errors in case try fails\n",
    "        try:\n",
    "            with open(file, \"r\") as f:\n",
    "                search_doc = f.read()\n",
    "            return search_doc\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Error: File not found - {file}: {e}\")\n",
    "        except IOError as e:\n",
    "            print(f\"Error opening or reading file {file}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "    def create_corpus(self, corpus_folder):\n",
    "        assert Path(self.directory+corpus_folder).is_dir(), \"The input directory does not exist.\"\n",
    "        files = Path(self.directory+corpus_folder).glob('*')\n",
    "        for file in files:\n",
    "            if file.suffixes == [\".txt\"]:\n",
    "                try:\n",
    "                    self.name_list.append(file.name)\n",
    "                    with open(file, \"r\") as f:\n",
    "                        self.corpus.append(f.read())\n",
    "                except FileNotFoundError as e:\n",
    "                    print(f\"Error: File not found - {file}: {e}\")\n",
    "                except IOError as e:\n",
    "                    print(f\"Error opening or reading file {file}: {e}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"An unexpected error occurred: {e}\")\n",
    "                \n",
    "            else: print(f\"The following file could not be uploaded as it is no in .txt format: {file.name}\")\n",
    "        self.dictionary = self.create_dictionary()\n",
    "\n",
    "    def update_corpus(self,corpus_folder):\n",
    "        assert Path(self.directory+corpus_folder).is_dir(), \"The input directory does not exist. Please input an existing corpus folder to upadate the corpus.\"\n",
    "        self.clear_corpus()\n",
    "        self.clear_name_list()\n",
    "        self.create_corpus(corpus_folder)\n",
    "        print(\"The corpus was successfully updated.\")\n",
    "\n",
    "    def process_text(self, text): #function to extract words from string\n",
    "        #extract words from string and return in lower case\n",
    "        return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "    def create_dictionary(self): #function to create a dictionary from the corpus documents\n",
    "        #iterate through all documents from the corpus\n",
    "        for document in self.corpus:\n",
    "            #extract all words in lower case from the string\n",
    "            #save words as a set and add words to the dictionary by building the union\n",
    "            words = self.process_text(document)\n",
    "            new_words = set(words)\n",
    "            self.dictionary = self.dictionary.union(new_words)\n",
    "        return self.dictionary\n",
    "\n",
    "    def document_to_vector(self, document): #function to convert a document (list of document words) into a binary vector\n",
    "        # Convert a document into a binary vector\n",
    "        # uses process_text function to convert document into a list of words\n",
    "        word_list = self.process_text(document)\n",
    "        # iterates through the dictionary  \n",
    "        # appends 1 when word is in the list of words from the document  \n",
    "        # appends 0 when word is not in the list of words from the document  \n",
    "        doc_vector = np.array([1 if word in word_list else 0 for word in self.dictionary])\n",
    "        return doc_vector\n",
    "\n",
    "    def freq_vector(self, document): #Function to convert a document (list of document words) into a frequency vector\n",
    "        #Convert a document into a list of words\n",
    "        word_list = self.process_text(document)\n",
    "        #Count occurrences of each word in the document\n",
    "        word_counts = {word: word_list.count(word) for word in set(word_list)}\n",
    "        #Create the frequency vector\n",
    "        freq_vector = np.array([word_counts.get(word, 0) for word in self.dictionary])\n",
    "        return freq_vector\n",
    "\n",
    "    def dot_similarity(self, search_vector): #function to compute similarities by using dot product\n",
    "        similarity_dic = {}\n",
    "        #use \"for i, doc_vector\" to also get index of the iteration -> used to get the document from the corpus\n",
    "        for i, doc_vector in enumerate(self.doc_vectors):\n",
    "            similarity = np.dot(doc_vector, search_vector)\n",
    "            doc_name = self.name_list[i]\n",
    "            similarity_dic.update({doc_name: similarity})\n",
    "        return similarity_dic\n",
    "\n",
    "    def jac_similarity(self, search_doc, search_vector): #function to compute similarities by using Jaccard Index\n",
    "        similarity_dic = {}\n",
    "        #create set of all words in the search document\n",
    "        #search_len = len(set(self.process_text(search_doc)))\n",
    "        for i, doc_vector in enumerate(self.doc_vectors):\n",
    "            #create set of all words for each document in the corpus\n",
    "            #cor_len = len(set(self.process_text(self.corpus[i])))\n",
    "            #divide the dot product by the number of words in the union of search_doc and doc from corpus\n",
    "            similarity = np.dot(doc_vector, search_vector) / (len(set(self.process_text(search_doc)))+ len(set(self.process_text(self.corpus[i]))))\n",
    "            #get name from name_list by indexing from the name_list\n",
    "            doc_name = self.name_list[i]\n",
    "            similarity_dic.update({doc_name: similarity})\n",
    "        return similarity_dic\n",
    "\n",
    "    def euc_similarity(self, search_vector): #function to compute similarities by using the euclidean distance\n",
    "        similarity_dic = {}\n",
    "        for i, doc_vector in enumerate(self.doc_vectors):\n",
    "            similarity = np.linalg.norm(doc_vector - search_vector)\n",
    "            doc_name = self.name_list[i]\n",
    "            similarity_dic.update({doc_name: similarity})\n",
    "        return similarity_dic\n",
    "\n",
    "    def cosine_similarity(self, search_vector): #function to compute similarities by using the cosine similarity\n",
    "        similarity_dic = {}\n",
    "        for i, doc_vector in enumerate(self.doc_vectors):\n",
    "            #dot product of the seach vector and document vector is divided by the product of the lengths of the vectors\n",
    "            similarity = np.dot(doc_vector, search_vector) / (np.linalg.norm(doc_vector) * np.linalg.norm(search_vector))\n",
    "            doc_name = self.name_list[i]\n",
    "            similarity_dic.update({doc_name: similarity})\n",
    "        return similarity_dic\n",
    "\n",
    "    def compute_similarity(self, search_doc, method): #function which is triggered by user to compute similarity\n",
    "        #sends search document string to load search document function and gets the content of the file as string\n",
    "        search_doc = self.load_search_doc(search_doc)\n",
    "        #create biary vector of search document\n",
    "        search_vector = self.document_to_vector(search_doc)\n",
    "        #create array of binary vectors of corpus documents\n",
    "        self.doc_vectors = np.array([self.document_to_vector(document) for document in self.corpus])\n",
    "\n",
    "        #if statements to assess which method is chosen\n",
    "        #sends vectors and corpus to computing function\n",
    "        if method == \"Dot Product\":\n",
    "            similarities = self.dot_similarity(search_vector)\n",
    "            #convert dictionary into data frame for formatted output and possibility to easily order results\n",
    "            similarities_df = pd.DataFrame(similarities.items(), columns=['Document', 'Similarity'])\n",
    "            similarities_df.sort_values([\"Similarity\"], ascending=False, inplace=True)\n",
    "            print(\"Dot Product: \\n\", similarities_df, \"\\nThe higher the dot product the higher the similarity.\" )\n",
    "        elif method == \"Jaccard Index\":\n",
    "            similarities = self.jac_similarity(search_doc, search_vector)\n",
    "            similarities_df = pd.DataFrame(similarities.items(), columns=['Document', 'Similarity'])\n",
    "            similarities_df.sort_values([\"Similarity\"], ascending=False, inplace=True)\n",
    "            print(\"Jaccard Index: \\n\", similarities_df, \"\\nThe higher the Jaccard Index the higher the similarity.\" )\n",
    "        elif method == \"Euclidean Distance\":\n",
    "            similarities = self.euc_similarity(search_vector)\n",
    "            similarities_df = pd.DataFrame(similarities.items(), columns=['Document', 'Similarity'])\n",
    "            similarities_df.sort_values([\"Similarity\"], ascending=True, inplace=True)\n",
    "            print(\"Euclidean Distance: \\n\", similarities_df, \"\\nThe lower the Euclidean Distance the higher the similarity.\" )\n",
    "        elif method == \"Cosine Similarity\":\n",
    "            similarities = self.cosine_similarity(search_vector)\n",
    "            similarities_df = pd.DataFrame(similarities.items(), columns=['Document', 'Similarity'])\n",
    "            similarities_df.sort_values([\"Similarity\"], ascending=False, inplace=True)\n",
    "            print(\"Cosine Similarity: \\n\", similarities_df, \"\\nThe lower the Cosine Similarity the higher the similarity.\" )\n",
    "        else:\n",
    "            print(\"Unknown method. Please input one of the following Methods: \\n\", \"Dot Product, \", \"Cosine Similarity, \", \"Jaccard Index, \", \"Euclidean Distance\")\n",
    "            return None\n",
    "        \n",
    "        \n",
    "        #return similarities_df\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialise the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "#requires directory path as input\n",
    "directory = input(\"Please enter the path to the folder containing the files for which you want to compute the stext similiarities: \")\n",
    "analyzer = DocumentSimilarityAnalyzer(directory)\n",
    "\n",
    "#set directory path by pasting th string\n",
    "directory = \"\"\n",
    "analyzer = DocumentSimilarityAnalyzer(directory)\n",
    "\n",
    "\n",
    "#JONATHAN\n",
    "#/Users/jonathan/Library/Mobile Documents/com~apple~CloudDocs/Master/Foundations of Data Science/Assignment/ds_final_assignment/\n",
    "\n",
    "#NICK\n",
    "#/Users/nickolasreinecke/Desktop/FDS Q3/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following file could not be uploaded as it is no in .txt format: Error_Test.docx\n",
      "['The fifth document contains words that are not present in the search document.\\n', 'This is the fourth document. It shares some common words with the other documents.\\n', 'This is the first document. It contains some words for testing.', 'Document number three is different from the others. It has unique words.', 'The second document is here. It shares some words with the first document.']\n",
      "['doc5.txt', 'doc4.txt', 'doc1.txt', 'doc3.txt', 'doc2.txt']\n",
      "{'first', 'three', 'number', 'is', 'others', 'with', 'some', 'present', 'documents', 'other', 'that', 'words', 'not', 'the', 'fourth', 'has', 'it', 'search', 'for', 'second', 'from', 'shares', 'document', 'testing', 'this', 'fifth', 'common', 'here', 'contains', 'in', 'unique', 'different', 'are'}\n",
      "The following file could not be uploaded as it is no in .txt format: Error_Test.docx\n",
      "The corpus was successfully updated.\n",
      "['The fifth document contains words that are not present in the search document.\\n', 'This is the fourth document. It shares some common words with the other documents.\\n', 'This is the first document. It contains some words for testing.', 'Document number three is different from the others. It has unique words.', 'The second document is here. It shares some words with the first document.']\n",
      "['doc5.txt', 'doc4.txt', 'doc1.txt', 'doc3.txt', 'doc2.txt']\n",
      "{'first', 'three', 'number', 'is', 'others', 'with', 'some', 'present', 'documents', 'other', 'that', 'words', 'not', 'the', 'fourth', 'has', 'it', 'search', 'for', 'second', 'from', 'shares', 'document', 'testing', 'this', 'fifth', 'common', 'here', 'contains', 'in', 'unique', 'different', 'are'}\n"
     ]
    }
   ],
   "source": [
    "#upload documents for corpus\n",
    "analyzer.create_corpus(\"Corpus_Docs\")\n",
    "analyzer.print_corpus()\n",
    "analyzer.print_name()\n",
    "analyzer.print_dictionary()\n",
    "\n",
    "\n",
    "analyzer.update_corpus(\"Corpus_Docs\")\n",
    "analyzer.print_corpus()\n",
    "analyzer.print_name()\n",
    "analyzer.print_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot Product: \n",
      "    Document  Similarity\n",
      "2  doc1.txt           7\n",
      "1  doc4.txt           6\n",
      "4  doc2.txt           6\n",
      "3  doc3.txt           5\n",
      "0  doc5.txt           4 \n",
      "The higher the dot product the higher the similarity.\n",
      "Jaccard Index: \n",
      "    Document  Similarity\n",
      "2  doc1.txt    0.291667\n",
      "4  doc2.txt    0.250000\n",
      "1  doc4.txt    0.230769\n",
      "3  doc3.txt    0.200000\n",
      "0  doc5.txt    0.166667 \n",
      "The higher the Jaccard Index the higher the similarity.\n",
      "Euclidean Distance: \n",
      "    Document  Similarity\n",
      "2  doc1.txt    2.449490\n",
      "4  doc2.txt    2.828427\n",
      "1  doc4.txt    3.162278\n",
      "3  doc3.txt    3.316625\n",
      "0  doc5.txt    3.464102 \n",
      "The lower the Euclidean Distance the higher the similarity.\n",
      "Cosine Similarity: \n",
      "    Document  Similarity\n",
      "2  doc1.txt    0.703526\n",
      "4  doc2.txt    0.603023\n",
      "1  doc4.txt    0.554700\n",
      "3  doc3.txt    0.481125\n",
      "0  doc5.txt    0.402015 \n",
      "The lower the Cosine Similarity the higher the similarity.\n"
     ]
    }
   ],
   "source": [
    "#cimpute similarities\n",
    "analyzer.compute_similarity(\"search_doc.txt\", \"Dot Product\")\n",
    "analyzer.compute_similarity(\"search_doc.txt\", \"Jaccard Index\")\n",
    "analyzer.compute_similarity(\"search_doc.txt\", \"Euclidean Distance\")\n",
    "analyzer.compute_similarity(\"search_doc.txt\", \"Cosine Similarity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Triggering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputted path is not valid. Please check your input.\n"
     ]
    }
   ],
   "source": [
    "#input wrong directory\n",
    "analyzer = DocumentSimilarityAnalyzer(\"adf3a/asdaf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The input directory does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/jonathan/Library/Mobile Documents/com~apple~CloudDocs/Master/Foundations of Data Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb Zelle 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jonathan/Library/Mobile%20Documents/com~apple~CloudDocs/Master/Foundations%20of%20Data%20Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#create corpus with not valid folder name\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jonathan/Library/Mobile%20Documents/com~apple~CloudDocs/Master/Foundations%20of%20Data%20Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb#X23sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m analyzer\u001b[39m.\u001b[39;49mcreate_corpus(\u001b[39m\"\u001b[39;49m\u001b[39mCorpus_Dcs\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/Users/jonathan/Library/Mobile Documents/com~apple~CloudDocs/Master/Foundations of Data Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb Zelle 8\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathan/Library/Mobile%20Documents/com~apple~CloudDocs/Master/Foundations%20of%20Data%20Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb#X23sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_corpus\u001b[39m(\u001b[39mself\u001b[39m, corpus_folder):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jonathan/Library/Mobile%20Documents/com~apple~CloudDocs/Master/Foundations%20of%20Data%20Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb#X23sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     \u001b[39massert\u001b[39;00m Path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdirectory\u001b[39m+\u001b[39mcorpus_folder)\u001b[39m.\u001b[39mis_dir(), \u001b[39m\"\u001b[39m\u001b[39mThe input directory does not exist.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathan/Library/Mobile%20Documents/com~apple~CloudDocs/Master/Foundations%20of%20Data%20Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb#X23sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     files \u001b[39m=\u001b[39m Path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdirectory\u001b[39m+\u001b[39mcorpus_folder)\u001b[39m.\u001b[39mglob(\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathan/Library/Mobile%20Documents/com~apple~CloudDocs/Master/Foundations%20of%20Data%20Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb#X23sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m files:\n",
      "\u001b[0;31mAssertionError\u001b[0m: The input directory does not exist."
     ]
    }
   ],
   "source": [
    "#create corpus with not valid folder name\n",
    "analyzer.create_corpus(\"Corpus_Dcs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The input directory does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/jonathan/Library/Mobile Documents/com~apple~CloudDocs/Master/Foundations of Data Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb Zelle 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jonathan/Library/Mobile%20Documents/com~apple~CloudDocs/Master/Foundations%20of%20Data%20Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb#X24sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#update corpus with not valid folder name\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jonathan/Library/Mobile%20Documents/com~apple~CloudDocs/Master/Foundations%20of%20Data%20Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb#X24sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m analyzer\u001b[39m.\u001b[39;49mcreate_corpus(\u001b[39m\"\u001b[39;49m\u001b[39mCorus_Docs\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/Users/jonathan/Library/Mobile Documents/com~apple~CloudDocs/Master/Foundations of Data Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb Zelle 9\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathan/Library/Mobile%20Documents/com~apple~CloudDocs/Master/Foundations%20of%20Data%20Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb#X24sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_corpus\u001b[39m(\u001b[39mself\u001b[39m, corpus_folder):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jonathan/Library/Mobile%20Documents/com~apple~CloudDocs/Master/Foundations%20of%20Data%20Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb#X24sZmlsZQ%3D%3D?line=53'>54</a>\u001b[0m     \u001b[39massert\u001b[39;00m Path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdirectory\u001b[39m+\u001b[39mcorpus_folder)\u001b[39m.\u001b[39mis_dir(), \u001b[39m\"\u001b[39m\u001b[39mThe input directory does not exist.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathan/Library/Mobile%20Documents/com~apple~CloudDocs/Master/Foundations%20of%20Data%20Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb#X24sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     files \u001b[39m=\u001b[39m Path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdirectory\u001b[39m+\u001b[39mcorpus_folder)\u001b[39m.\u001b[39mglob(\u001b[39m'\u001b[39m\u001b[39m*\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathan/Library/Mobile%20Documents/com~apple~CloudDocs/Master/Foundations%20of%20Data%20Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb#X24sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m files:\n",
      "\u001b[0;31mAssertionError\u001b[0m: The input directory does not exist."
     ]
    }
   ],
   "source": [
    "#update corpus with not valid folder name\n",
    "analyzer.create_corpus(\"Corus_Docs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unknown method. Please input one of the following Methods: \n",
      " Dot Product,  Cosine Similarity,  Jaccards Index,  Euclidean Distance\n"
     ]
    }
   ],
   "source": [
    "#input wrong method\n",
    "analyzer.compute_similarity(\"search_doc.txt\", \"Dots Product\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "The inputted file does not exist at that directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/jonathan/Library/Mobile Documents/com~apple~CloudDocs/Master/Foundations of Data Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb Zelle 12\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jonathan/Library/Mobile%20Documents/com~apple~CloudDocs/Master/Foundations%20of%20Data%20Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#input not valid search document\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jonathan/Library/Mobile%20Documents/com~apple~CloudDocs/Master/Foundations%20of%20Data%20Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb#X30sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m analyzer\u001b[39m.\u001b[39;49mcompute_similarity(\u001b[39m\"\u001b[39;49m\u001b[39msearch_docs.txt\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mDot Product\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/Users/jonathan/Library/Mobile Documents/com~apple~CloudDocs/Master/Foundations of Data Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb Zelle 12\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jonathan/Library/Mobile%20Documents/com~apple~CloudDocs/Master/Foundations%20of%20Data%20Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb#X30sZmlsZQ%3D%3D?line=151'>152</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_similarity\u001b[39m(\u001b[39mself\u001b[39m, search_doc, method): \u001b[39m#function which is triggered by user to compute similarity\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jonathan/Library/Mobile%20Documents/com~apple~CloudDocs/Master/Foundations%20of%20Data%20Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb#X30sZmlsZQ%3D%3D?line=152'>153</a>\u001b[0m     \u001b[39m#sends search document string to load search document function and gets the content of the file as string\u001b[39;00m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/jonathan/Library/Mobile%20Documents/com~apple~CloudDocs/Master/Foundations%20of%20Data%20Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb#X30sZmlsZQ%3D%3D?line=153'>154</a>\u001b[0m     search_doc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_search_doc(search_doc)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jonathan/Library/Mobile%20Documents/com~apple~CloudDocs/Master/Foundations%20of%20Data%20Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb#X30sZmlsZQ%3D%3D?line=154'>155</a>\u001b[0m     \u001b[39m#create biary vector of search document\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/jonathan/Library/Mobile%20Documents/com~apple~CloudDocs/Master/Foundations%20of%20Data%20Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb#X30sZmlsZQ%3D%3D?line=155'>156</a>\u001b[0m     search_vector \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdocument_to_vector(search_doc)\n",
      "\u001b[1;32m/Users/jonathan/Library/Mobile Documents/com~apple~CloudDocs/Master/Foundations of Data Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb Zelle 12\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathan/Library/Mobile%20Documents/com~apple~CloudDocs/Master/Foundations%20of%20Data%20Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb#X30sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_search_doc\u001b[39m(\u001b[39mself\u001b[39m, doc_name): \u001b[39m#function to load the search document from drive\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathan/Library/Mobile%20Documents/com~apple~CloudDocs/Master/Foundations%20of%20Data%20Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb#X30sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathan/Library/Mobile%20Documents/com~apple~CloudDocs/Master/Foundations%20of%20Data%20Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb#X30sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m     \u001b[39m#open file by using path() -> to make it operateable on windows and mac systems\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/jonathan/Library/Mobile%20Documents/com~apple~CloudDocs/Master/Foundations%20of%20Data%20Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb#X30sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39massert\u001b[39;00m Path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdirectory\u001b[39m+\u001b[39mdoc_name)\u001b[39m.\u001b[39mis_file(), \u001b[39m\"\u001b[39m\u001b[39mThe inputted file does not exist at that directory.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathan/Library/Mobile%20Documents/com~apple~CloudDocs/Master/Foundations%20of%20Data%20Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb#X30sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     file \u001b[39m=\u001b[39m Path(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdirectory \u001b[39m+\u001b[39m doc_name)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathan/Library/Mobile%20Documents/com~apple~CloudDocs/Master/Foundations%20of%20Data%20Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb#X30sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     \u001b[39m#open and read search file\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/jonathan/Library/Mobile%20Documents/com~apple~CloudDocs/Master/Foundations%20of%20Data%20Science/Assignment/ds_final_assignment/FDS_Q3_Class_new.ipynb#X30sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m     \u001b[39m#throw errors in case try fails\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: The inputted file does not exist at that directory."
     ]
    }
   ],
   "source": [
    "#input not valid search document\n",
    "analyzer.compute_similarity(\"search_docs.txt\", \"Dot Product\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
