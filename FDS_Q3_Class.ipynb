{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Document Similarity\n",
    "Create a python program that will compute the text document similarity between different docu- ments. Your implementation will take a list of documents as an input text corpus, and it will compute a dictionary of words for the given corpus. Later, when a new document (i.e, search document) is provided, your implementation should provide a list of documents that are similar to the given search document, in descending order of their similarity with the search document.\n",
    "For computing similarity between any two documents in our question, you can use the following distance measures (optionally, you can also use any other measure as well).\n",
    "1. dot product between the two vectors\n",
    "2. distance norm (or Euclidean distance) between two vectors .e.g. || u âˆ’ v ||\n",
    "\n",
    "As part of answering the question, you can also compare and comment on which of the two methods (or any other measure if you have used some other measure) will perform better and what are the reasons for it.\n",
    "\n",
    "Hint A text document can be represented as a word vector against a given dictionary of words. So first, compute the dictionary of words for a given text corpus containing the unique words from the documents of the given corpus. Then transform every text document of the given corpus into vector form, i.e., creating a word vector where 0 indicates the word is not in the document, and 1 indicates that the word is present in the given document. In our question, a text document is just represented as a string, so the text corpus is nothing but a list of strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "**def_input_corpus**: \n",
    "- input text corpus containing of multiple strings CHECK \n",
    "- words from corpus to dictionary CHECK\n",
    "- split inpt strings into words (account for .:,;!&/()=\"\")) CHECK\n",
    "- append words to a library (list of distinct words) CHECK\n",
    "- create vektors fo text documents CHECK\n",
    "\n",
    "\n",
    "\n",
    "**def_input_new_document**:\n",
    "- create vektor for text document based on corpus CHECK\n",
    "- calculate difference between input text and every existing text document CHECK\n",
    "- create a list of the documents and their similarity rating -> dictionary used -> probably convert it to df in the end\n",
    "\n",
    "\n",
    "**things to add**:\n",
    "- document names CHECK\n",
    "- reading of documents from drive path (.txt file) CHECK -> test with windows \n",
    "- word frequency for documents -> not binary vector anymore -> does that make sense?\n",
    "- change dictionary to set instead of list CHECK\n",
    "- combine the similarity methods and call them individually be inputting \"method = ...\" -> similar to ChatGPT Code -> CHECK\n",
    "- add cosine similarity method\n",
    "\n",
    "Error Handling: \n",
    "- Error when document is already part of the corpus (asserted by checking if already in name list) CHECK\n",
    "- Error when search document name and document name for corpus are not in the folder CHECK\n",
    "- Error when file is empty (when contains no words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "class DocumentSimilarityAnalyzer:\n",
    "    def __init__(self, directory):\n",
    "        self.directory = directory\n",
    "        self.dictionary = set()\n",
    "        self.corpus = [] #list of strings -> appended in the \"update corpus\" function\n",
    "        self.name_list = [] #list of strings -> appended in the \"update name\" function -> used to get document names\n",
    "\n",
    "    def clear_corpus(self):\n",
    "        self.corpus.clear()\n",
    "\n",
    "    def clear_name_list(self):\n",
    "        self.name_list.clear()\n",
    "\n",
    "    def load_search_doc(self, doc_name): #function to load the search document from drive\n",
    "        \n",
    "        #open file by using path() -> to make it operateable on windows and mac systems\n",
    "        file_to_open = Path(self.directory + doc_name)\n",
    "        \n",
    "        #open and read search file\n",
    "        #throw errors in case try fails\n",
    "        try:\n",
    "            with open(file_to_open, \"r\") as f:\n",
    "                search_doc = f.read()\n",
    "            return search_doc\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Error: File not found - {file_to_open}: {e}\")\n",
    "        except IOError as e:\n",
    "            print(f\"Error opening or reading file {file_to_open}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "    def update_corpus(self, doc_name): #function to input a new document for the corpus\n",
    "        #open file by using path() -> to make it operateable on windows and mac systems\n",
    "        file_to_open = Path(self.directory + doc_name)\n",
    "        #open and read files to append to the corpus\n",
    "        #throw errors in case try fails\n",
    "        try:\n",
    "            #assert if file is already on name list and therefore part of the corpus\n",
    "            #append file name to name_list when not already on name_list\n",
    "            assert doc_name not in self.name_list, f\"Document {doc_name} already uploaded, please choose another file.\"\n",
    "            self.name_list.append(doc_name)\n",
    "            with open(file_to_open, \"r\") as f:\n",
    "                self.corpus.append(f.read())\n",
    "            self.dictionary.update(self.create_dictionary())\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"Error: File not found - {file_to_open}: {e}\")\n",
    "        except IOError as e:\n",
    "            print(f\"Error opening or reading file {file_to_open}: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"An unexpected error occurred: {e}\")\n",
    "        return None # Return a sentinel value or handle the case appropriately\n",
    "\n",
    "    def process_text(self, text): #function to extract words from string\n",
    "        # extract words from string and return in lower case\n",
    "        return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "    def create_dictionary(self): #function to create a dictionary from the corpus documents\n",
    "        \n",
    "        #iterate through all documents from the corpus\n",
    "        for document in self.corpus:\n",
    "            #extract all words in lower case from the string\n",
    "            #save words as a set and add words to the dictionary by building the union\n",
    "            words = self.process_text(document)\n",
    "            new_words = set(words)\n",
    "            dictionary = dictionary.union(new_words)\n",
    "        return dictionary\n",
    "\n",
    "    def document_to_vector(self, document): #function to convert a document (list of document words) into a binary vector\n",
    "        # Convert a document into a binary vector\n",
    "        # uses process_text function to convert document into a list of words\n",
    "        word_list = self.process_text(document)\n",
    "        # iterates through the dictionary  \n",
    "        # appends 1 when word is in the list of words from the document  \n",
    "        # appends 0 when word is not in the list of words from the document  \n",
    "        doc_vector = np.array([1 if word in word_list else 0 for word in self.dictionary])\n",
    "        return doc_vector\n",
    "\n",
    "    def freq_vector(self, document): #Function to convert a document (list of document words) into a frequency vector\n",
    "        #Convert a document into a list of words\n",
    "        word_list = self.process_text(document)\n",
    "        #Count occurrences of each word in the document\n",
    "        word_counts = {word: word_list.count(word) for word in set(word_list)}\n",
    "        #Create the frequency vector\n",
    "        freq_vector = np.array([word_counts.get(word, 0) for word in self.dictionary])\n",
    "        return freq_vector\n",
    "\n",
    "    def dot_similarity(self, search_vector): #function to compute similarities by using dot product\n",
    "        similarity_dic = {}\n",
    "        #use \"for i, doc_vector\" to also get index of the iteration -> used to get the document from the corpus\n",
    "        for i, doc_vector in enumerate(self.doc_vectors):\n",
    "            similarity = np.dot(doc_vector, search_vector)\n",
    "            doc_name = self.name_list[i]\n",
    "            similarity_dic.update({doc_name: similarity})\n",
    "        return similarity_dic\n",
    "\n",
    "    def jac_similarity(self, search_vector): #function to compute similarities by using Jaccard Index\n",
    "        similarity_dic = {}\n",
    "        for i, doc_vector in enumerate(self.doc_vectors):\n",
    "            cor_len = len(self.process_text(self.corpus[i]))\n",
    "            search_len = len(self.process_text(str(search_vector)))\n",
    "            #divide the dot product by the number of words in the union of search_doc and doc from corpus\n",
    "            similarity = np.dot(doc_vector, search_vector) / (search_len + cor_len)\n",
    "            #get name from name_list by indexing from the name_list\n",
    "            doc_name = self.name_list[i]\n",
    "            similarity_dic.update({doc_name: similarity})\n",
    "        return similarity_dic\n",
    "\n",
    "    def euc_similarity(self, search_vector): #function to compute similarities by using the euclidean distance\n",
    "        similarity_dic = {}\n",
    "        for i, doc_vector in enumerate(self.doc_vectors):\n",
    "            similarity = np.linalg.norm(doc_vector - search_vector)\n",
    "            doc_name = self.name_list[i]\n",
    "            similarity_dic.update({doc_name: similarity})\n",
    "        return similarity_dic\n",
    "\n",
    "    def compute_similarity(self, search_doc, method): #function which is triggered by user to compute similarity\n",
    "        #sends search document string to load search document function and gets the content of the file as string\n",
    "        search_doc = self.load_search_doc(search_doc)\n",
    "        #create biary vector of search document\n",
    "        search_vector = self.document_to_vector(search_doc)\n",
    "        #create array of binary vectors of corpus documents\n",
    "        self.doc_vectors = np.array([self.document_to_vector(document) for document in self.corpus])\n",
    "\n",
    "        #if statements to assess which method is chosen\n",
    "        #sends vectors and corpus to computing function\n",
    "        if method == \"Dot Product\":\n",
    "            similarities = self.dot_similarity(search_vector)\n",
    "        elif method == \"Jaccard Index\":\n",
    "            similarities = self.jac_similarity(search_vector)\n",
    "        elif method == \"Euclidean Distance\":\n",
    "            similarities = self.euc_similarity(search_vector)\n",
    "        else:\n",
    "            print(\"Unknown method\")\n",
    "            return None\n",
    "\n",
    "        #convert dictionary into data frame for formatted output and possibility to easily order results\n",
    "        similarities_df = pd.DataFrame(similarities.items(), columns=['Document', 'Similarity'])\n",
    "        similarities_df.sort_values([\"Similarity\"], ascending=False, inplace=True)\n",
    "        print(f\"{method}: \\n\", similarities_df)\n",
    "        #return similarities_df\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot Product: \n",
      "    Document  Similarity\n",
      "3  doc4.txt           5\n",
      "2  doc3.txt           3\n",
      "0  doc1.txt           2\n",
      "1  doc2.txt           1\n",
      "Jaccard Index: \n",
      "    Document  Similarity\n",
      "3  doc4.txt    0.312500\n",
      "2  doc3.txt    0.187500\n",
      "0  doc1.txt    0.166667\n",
      "1  doc2.txt    0.083333\n",
      "Euclidean Distance: \n",
      "    Document  Similarity\n",
      "1  doc2.txt    2.645751\n",
      "2  doc3.txt    2.449490\n",
      "0  doc1.txt    2.236068\n",
      "3  doc4.txt    1.414214\n"
     ]
    }
   ],
   "source": [
    "#replace directory with file path to the folder in which the documents and the code-file are located\n",
    "directory= \"/Users/jonathan/Library/Mobile Documents/com~apple~CloudDocs/Master/Foundations of Data Science/Assignment/Final Assignment/\"\n",
    "analyzer = DocumentSimilarityAnalyzer(directory)\n",
    "\n",
    "analyzer.update_corpus(\"doc1.txt\")\n",
    "analyzer.update_corpus(\"doc2.txt\")\n",
    "analyzer.update_corpus(\"doc3.txt\")\n",
    "analyzer.update_corpus(\"doc4.txt\")\n",
    "analyzer.compute_similarity(\"search_doc.txt\", \"Dot Product\")\n",
    "analyzer.compute_similarity(\"search_doc.txt\", \"Jaccard Index\")\n",
    "analyzer.compute_similarity(\"search_doc.txt\", \"Euclidean Distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "directory = \"/path/to/your/files/\"\n",
    "analyzer = DocumentSimilarityAnalyzer(directory)\n",
    "analyzer.update_corpus(\"example_doc1.txt\")\n",
    "analyzer.update_corpus(\"example_doc2.txt\")\n",
    "analyzer.compute_similarity(\"search_doc.txt\", \"Dot Product\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
